{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ac59b5-bbfa-480e-ab6a-3bdf2ac58069",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d27dd96-c9d3-4812-91fc-1c93e7b79aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BLOOM model and tokenizer\n",
    "model_name = \"bigscience/bloomz-560m\"  # Model that works better for Q/A\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(model_name)\n",
    "model = BloomForCausalLM.from_pretrained(model_name).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "024e1f37-e5a0-42fa-aae5-669cbaf33efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the 5 tallest mountains in the world? Mount Kilimanjaro, Mount Everest, Mount Kilimanjaro, Mount Kilimanjaro, and Mount Kilimanjaro\n"
     ]
    }
   ],
   "source": [
    "# Define text for interpretation\n",
    "input_text = \"What are the 5 tallest mountains in the world?\" \n",
    "# Tokenize the input text and get the input tensor\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs, max_new_tokens=20,\n",
    "                        temperature=0.05,\n",
    "                        top_p=0.9,#nucleus sampling\n",
    "                        do_sample=True )\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4c262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e99a5e3e-8de4-4410-a941-06f03cb354f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:  Mount Kilimanjaro, Mount Everest, Mount Kilimanjaro, Mount\n",
      "\n",
      "Top 5 Logits for Each New Token:\n",
      "\n",
      "Token 1: ' Mount'\n",
      "     Mount: 397.5774\n",
      "     Mt: 396.3606\n",
      "     Everest: 396.0087\n",
      "     Kilimanjaro: 395.5673\n",
      "     Alps: 395.3434\n",
      "\n",
      "Token 2: ' Kilimanjaro'\n",
      "     Kilimanjaro: 388.0668\n",
      "     Everest: 387.4675\n",
      "     Rush: 385.2826\n",
      "     Kin: 383.7083\n",
      "     Kenya: 383.6555\n",
      "\n",
      "Token 3: ','\n",
      "    ,: 419.4991\n",
      "    </s>: 419.4828\n",
      "     and: 417.3188\n",
      "     (: 416.9478\n",
      "     in: 415.8520\n",
      "\n",
      "Token 4: ' Mount'\n",
      "     Mount: 403.3391\n",
      "     Kilimanjaro: 401.9385\n",
      "     Tanzania: 400.4769\n",
      "     Mt: 400.3781\n",
      "     the: 400.2496\n",
      "\n",
      "Token 5: ' Everest'\n",
      "     Everest: 381.4550\n",
      "     Kilimanjaro: 381.0041\n",
      "     Et: 380.6830\n",
      "     Kenya: 379.9611\n",
      "     Rush: 379.8688\n",
      "\n",
      "Token 6: ','\n",
      "    ,: 424.3529\n",
      "    </s>: 420.8809\n",
      "     and: 419.6128\n",
      "     (: 418.7540\n",
      "     ,: 416.8163\n",
      "\n",
      "Token 7: ' Mount'\n",
      "     Mount: 402.5578\n",
      "     Mt: 400.0130\n",
      "     Kilimanjaro: 398.9368\n",
      "     the: 398.7545\n",
      "     Everest: 397.6899\n",
      "\n",
      "Token 8: ' Kilimanjaro'\n",
      "     Kilimanjaro: 379.1410\n",
      "     Kin: 378.5024\n",
      "     Et: 378.3369\n",
      "     Everest: 378.1898\n",
      "     N: 378.1757\n",
      "\n",
      "Token 9: ','\n",
      "    ,: 414.3104\n",
      "     and: 412.5128\n",
      "    </s>: 411.0688\n",
      "     Mount: 410.8495\n",
      "     summit: 409.9455\n",
      "\n",
      "Token 10: ' Mount'\n",
      "     Mount: 407.7656\n",
      "     Mt: 404.9834\n",
      "     Kilimanjaro: 404.2144\n",
      "     and: 403.8176\n",
      "     Everest: 403.1483\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Tokenize the initial prompt\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Number of new tokens to generate\n",
    "max_new_tokens = 10\n",
    "generated_tokens = []\n",
    "top_logits_per_token = []\n",
    "\n",
    "# Loop to generate each new token one at a time and get top 5 logits\n",
    "for _ in range(max_new_tokens):\n",
    "    # Pass the current input through the model to get logits\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids)\n",
    "    \n",
    "    # Get logits for the last token in the sequence\n",
    "    logits = outputs.logits[0, -1, :]  # Shape [vocab_size]\n",
    "    \n",
    "    # Get the top 5 tokens and their logits\n",
    "    top_k_logits, top_k_indices = torch.topk(logits, k=5)\n",
    "    \n",
    "    # Decode the top 5 tokens and clean up the Ġ prefix\n",
    "    top_k_tokens = [\n",
    "        tokenizer.decode([token_id]).replace(\"Ġ\", \"\") for token_id in top_k_indices\n",
    "    ]\n",
    "    \n",
    "    # Store the top 5 logits and corresponding tokens\n",
    "    top_logits_per_token.append(list(zip(top_k_tokens, top_k_logits.tolist())))\n",
    "    \n",
    "    # Select the most probable token (argmax) as the next token\n",
    "    next_token_id = top_k_indices[0].unsqueeze(0)\n",
    "    generated_tokens.append(next_token_id.item())\n",
    "    \n",
    "    # Update input_ids with the new token for the next iteration\n",
    "    input_ids = torch.cat([input_ids, next_token_id.unsqueeze(0)], dim=-1)\n",
    "\n",
    "# Decode the generated tokens and remove any remaining prefixes for clarity\n",
    "generated_text = tokenizer.decode(generated_tokens).replace(\"Ġ\", \"\")\n",
    "\n",
    "# Display the results\n",
    "print(f\"Generated Text: {generated_text}\\n\")\n",
    "print(\"Top 5 Logits for Each New Token:\")\n",
    "for i, token_info in enumerate(top_logits_per_token):\n",
    "    print(f\"\\nToken {i + 1}: '{tokenizer.decode([generated_tokens[i]]).replace('Ġ', '')}'\")\n",
    "    for token, logit in token_info:\n",
    "        print(f\"    {token}: {logit:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
